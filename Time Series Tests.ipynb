{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.ar_model import AR,ARResults\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EuStocks = pd.read_csv(\"EuIndices (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAX</th>\n",
       "      <th>SMI</th>\n",
       "      <th>CAC</th>\n",
       "      <th>FTSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>1628.75</td>\n",
       "      <td>1678.1</td>\n",
       "      <td>1772.8</td>\n",
       "      <td>2443.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1613.63</td>\n",
       "      <td>1688.5</td>\n",
       "      <td>1750.5</td>\n",
       "      <td>2460.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991-01-03</td>\n",
       "      <td>1606.51</td>\n",
       "      <td>1678.6</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>2448.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991-01-04</td>\n",
       "      <td>1621.04</td>\n",
       "      <td>1684.1</td>\n",
       "      <td>1708.1</td>\n",
       "      <td>2470.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1991-01-07</td>\n",
       "      <td>1618.16</td>\n",
       "      <td>1686.6</td>\n",
       "      <td>1723.1</td>\n",
       "      <td>2484.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DAX     SMI     CAC    FTSE\n",
       "1991-01-01  1628.75  1678.1  1772.8  2443.6\n",
       "1991-01-02  1613.63  1688.5  1750.5  2460.2\n",
       "1991-01-03  1606.51  1678.6  1718.0  2448.2\n",
       "1991-01-04  1621.04  1684.1  1708.1  2470.4\n",
       "1991-01-07  1618.16  1686.6  1723.1  2484.7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EuStocks_DF = pd.DataFrame(data = EuStocks.values, columns = ['0', 'DAX', 'SMI', 'CAC', 'FTSE'],\n",
    "                           index = pd.DatetimeIndex(start = '1991-01-01', periods = 1860, freq = 'B'))\n",
    "df = EuStocks_DF.drop(columns = ['0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dickey-Fuller Test (Stationary Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"DAX\" \n",
      "    -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 2.2958\n",
      " No. Lags Chosen       = 24\n",
      " Critical value 1%     = -3.434\n",
      " Critical value 5%     = -2.863\n",
      " Critical value 10%    = -2.568\n",
      " => P-Value = 0.999. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"SMI\" \n",
      "    -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 2.235\n",
      " No. Lags Chosen       = 22\n",
      " Critical value 1%     = -3.434\n",
      " Critical value 5%     = -2.863\n",
      " Critical value 10%    = -2.568\n",
      " => P-Value = 0.9989. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"CAC\" \n",
      "    -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 1.2864\n",
      " No. Lags Chosen       = 17\n",
      " Critical value 1%     = -3.434\n",
      " Critical value 5%     = -2.863\n",
      " Critical value 10%    = -2.568\n",
      " => P-Value = 0.9965. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"FTSE\" \n",
      "    -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 0.1061\n",
      " No. Lags Chosen       = 13\n",
      " Critical value 1%     = -3.434\n",
      " Critical value 5%     = -2.863\n",
      " Critical value 10%    = -2.568\n",
      " => P-Value = 0.9665. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "    p_value = output['pvalue'] \n",
    "    def adjust(val, length= 6): \n",
    "        return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key,val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")\n",
    "          \n",
    "# ADF Test on each column\n",
    "for name, column in df.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire dataset is non stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grangerâ€™s Causality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df.iloc[:1302]\n",
    "X_test=df.iloc[1302:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAX_x</th>\n",
       "      <th>SMI_x</th>\n",
       "      <th>CAC_x</th>\n",
       "      <th>FTSE_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DAX_y</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SMI_y</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CAC_y</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FTSE_y</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DAX_x   SMI_x   CAC_x  FTSE_x\n",
       "DAX_y   1.0000  0.0001  0.6516  0.0046\n",
       "SMI_y   0.1210  1.0000  0.0810  0.0055\n",
       "CAC_y   0.4228  0.0109  1.0000  0.2846\n",
       "FTSE_y  0.0216  0.0006  0.0147  1.0000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "maxlag=12\n",
    "test = 'ssr_chi2test'\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    X_train = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in X_train.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            X_train.loc[r, c] = min_p_value\n",
    "    X_train.columns = [var + '_x' for var in variables]\n",
    "    X_train.index = [var + '_y' for var in variables]\n",
    "    return X_train\n",
    "\n",
    "grangers_causation_matrix(X_train, variables = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None of the variables are causing effect on other on either direction. This is because p value >0.05 for some variables. If all are <0.05 then there is a causality effect between those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durbin Watson Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 is no autocorrelation.\n",
    "#### 0 to <2 is positive autocorrelation (common in time series data).\n",
    "#### 2 to 4 is negative autocorrelation (less common in time series data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  If there is any correlation left in the residuals, then, there is some pattern in the time series that is still left to be explained by the model. In that case, the typical course of action is to either increase the order of the model or induce more predictors into the system or look for a different algorithm to model the time series. So, checking for serial correlation is to ensure that the model is sufficiently able to explain the variances and patterns in the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "\n",
    "for col, val in zip(X_train.columns, out):\n",
    "    print((col), ':', round(val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
